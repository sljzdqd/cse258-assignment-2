{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "rating = [1, 2, 3, 4, 5]\n",
    "total_data = []\n",
    "for r in rating:\n",
    "    filename = 'data/Office_Products_5.json.gz_' + str(r) + '.0.txt'\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            total_data.append((line.strip('\\n'), r))\n",
    "random.shuffle(total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = total_data[:int(0.7*len(total_data))]\n",
    "dev_data = total_data[int(0.7*len(total_data)):int(0.85*len(total_data))]\n",
    "test_data = total_data[int(0.85*len(total_data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "503099\n",
      "107807\n",
      "107808\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(dev_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('rating_train.tsv', 'w') as f:\n",
    "    for d in train_data:\n",
    "        f.write(d[0] + '\\t' + str(d[1]) + '\\n')\n",
    "with open('rating_dev.tsv', 'w') as f:\n",
    "    for d in dev_data:\n",
    "        f.write(d[0] + '\\t' + str(d[1]) + '\\n')\n",
    "with open('rating_test.tsv', 'w') as f:\n",
    "    for d in test_data:\n",
    "        f.write(d[0] + '\\t' + str(d[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate train data with balanced label count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "r4 = []\n",
    "r5 = []\n",
    "r_other = []\n",
    "for d in train_data:\n",
    "    if d[1] == 4:\n",
    "        r4.append(d)\n",
    "    elif d[1] == 5:\n",
    "        r5.append(d)\n",
    "    else:\n",
    "        r_other.append(d)\n",
    "b_train_data = r_other + r4[:50000] + r5[:50000]\n",
    "random.shuffle(b_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164533\n"
     ]
    }
   ],
   "source": [
    "print(len(b_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr4 = []\n",
    "tr5 = []\n",
    "tr_other = []\n",
    "for d in test_data:\n",
    "    if d[1] == 4:\n",
    "        tr4.append(d)\n",
    "    elif d[1] == 5:\n",
    "        tr5.append(d)\n",
    "    else:\n",
    "        tr_other.append(d)\n",
    "b_test_data = tr_other + tr4[:10000] + tr5[:10000]\n",
    "random.shuffle(b_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33746\n"
     ]
    }
   ],
   "source": [
    "print(len(b_test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dr4 = []\n",
    "dr5 = []\n",
    "dr_other = []\n",
    "for d in dev_data:\n",
    "    if d[1] == 4:\n",
    "        dr4.append(d)\n",
    "    elif d[1] == 5:\n",
    "        dr5.append(d)\n",
    "    else:\n",
    "        dr_other.append(d)\n",
    "b_dev_data = dr_other + dr4[:10000] + dr5[:10000]\n",
    "random.shuffle(b_dev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('balanced_rating_train.tsv', 'w') as f:\n",
    "    for d in b_train_data:\n",
    "        f.write(d[0] + '\\t' + str(d[1]) + '\\n')\n",
    "with open('balanced_rating_dev.tsv', 'w') as f:\n",
    "    for d in b_dev_data:\n",
    "        f.write(d[0] + '\\t' + str(d[1]) + '\\n')\n",
    "with open('balanced_rating_test.tsv', 'w') as f:\n",
    "    for d in b_test_data:\n",
    "        f.write(d[0] + '\\t' + str(d[1]) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit into linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "corpus = []\n",
    "labels = []\n",
    "with open('balanced_rating_train.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        sent, label = line.strip('\\n').split('\\t')\n",
    "        corpus.append(sent)\n",
    "        labels.append(int(label))\n",
    "        \n",
    "test_corpus = []\n",
    "test_labels = []\n",
    "with open('balanced_rating_test.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        sent, label = line.strip('\\n').split('\\t')\n",
    "        test_corpus.append(sent)\n",
    "        test_labels.append(int(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus+test_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = X[:len(corpus)]\n",
    "test_X = X[len(corpus):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(train_X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = reg.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5040725130698294\n"
     ]
    }
   ],
   "source": [
    "print(MSE(pred, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratio in different rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.037861335442924755\n",
      "0.028793537653622844\n",
      "0.06161610339118146\n",
      "0.14883551746276577\n",
      "0.7228935060495052\n"
     ]
    }
   ],
   "source": [
    "c1 = 0\n",
    "c2 = 0\n",
    "c3 = 0\n",
    "c4 = 0\n",
    "c5 = 0\n",
    "for d in train_data:\n",
    "    if d[1] == 1:\n",
    "        c1 += 1\n",
    "    elif d[1] == 2:\n",
    "        c2 += 1\n",
    "    elif d[1] == 3:\n",
    "        c3 += 1\n",
    "    elif d[1] == 4:\n",
    "        c4 += 1\n",
    "    elif d[1] == 5:\n",
    "        c5 += 1\n",
    "print(c1/len(train_data))\n",
    "print(c2/len(train_data))\n",
    "print(c3/len(train_data))\n",
    "print(c4/len(train_data))\n",
    "print(c5/len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03831812110418522\n",
      "0.028393069159988127\n",
      "0.060793262095577325\n",
      "0.1492653606411398\n",
      "0.7232301869991096\n"
     ]
    }
   ],
   "source": [
    "c1 = 0\n",
    "c2 = 0\n",
    "c3 = 0\n",
    "c4 = 0\n",
    "c5 = 0\n",
    "for d in test_data:\n",
    "    if d[1] == 1:\n",
    "        c1 += 1\n",
    "    elif d[1] == 2:\n",
    "        c2 += 1\n",
    "    elif d[1] == 3:\n",
    "        c3 += 1\n",
    "    elif d[1] == 4:\n",
    "        c4 += 1\n",
    "    elif d[1] == 5:\n",
    "        c5 += 1\n",
    "print(c1/len(test_data))\n",
    "print(c2/len(test_data))\n",
    "print(c3/len(test_data))\n",
    "print(c4/len(test_data))\n",
    "print(c5/len(test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
