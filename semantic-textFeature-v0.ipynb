{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add text feature\n",
    "\n",
    "1. number of words\n",
    "2. avg word length\n",
    "3. number of sentence\n",
    "4. avg number of words in a sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use top 1000 unigram and Tf Idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "sent_list = []\n",
    "labels = []\n",
    "with open('balance_train.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        sent, label = line.strip('\\n').split('\\t')\n",
    "        labels.append(int(label))\n",
    "        words = sent.split(' ')\n",
    "        pure_words = []\n",
    "        for w in words:\n",
    "            if w not in string.punctuation:\n",
    "                pure_words.append(w)\n",
    "        sent_list.append(pure_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "unigram = defaultdict(int)\n",
    "for sent in sent_list:\n",
    "    for w in sent:\n",
    "        unigram[w] += 1\n",
    "unigram = sorted(unigram.items(), key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000_unigram = unigram[:1000]\n",
    "uniwords = [i[0] for i in top1000_unigram]\n",
    "uniwordId = dict(zip(uniwords, range(len(uniwords))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_tf(word, sent):\n",
    "    sent_len = len(sent)\n",
    "    word_count = sent.count(word)\n",
    "    tf = word_count/sent_len\n",
    "    return tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def calc_idf(word, sents):\n",
    "    doc_num = len(sents)\n",
    "    word_count = 0\n",
    "    for s in sents:\n",
    "        if word in s:\n",
    "            word_count += 1\n",
    "    return math.log(doc_num/word_count, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniword_tfidf = defaultdict(dict)\n",
    "for word in uniwords:\n",
    "    uniword_tfidf[word]['idf'] = calc_idf(word, sent_list)\n",
    "sentId = 0\n",
    "for sent in sent_list:\n",
    "    for word in sent:\n",
    "        if word in uniwords:\n",
    "            uniword_tfidf[word][sentId] = calc_tf(word, sent)\n",
    "    sentId += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = []\n",
    "sentId = 0\n",
    "for sent in sent_list:\n",
    "    feat = [0]*len(uniwords)\n",
    "    for word in sent:\n",
    "        if word in uniwords:\n",
    "            idf = uniword_tfidf[word]['idf']\n",
    "            tf = uniword_tfidf[word][sentId]\n",
    "            feat[uniwordId[word]] = tf*idf\n",
    "    train_X.append(feat)\n",
    "    sentId += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression().fit(train_X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = clf.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = list(zip(theta, uniwords + ['constant_feat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(-13.284070698683689, 'return'), (-12.660907179679352, 'disappoint'), (-12.57235126798869, \"n't\"), (-11.760267543605465, 'not'), (-9.282087864652958, 'wast'), (-9.155801581836393, 'poor'), (-8.965083058001548, 'howev'), (-8.067596958535928, 'unfortun'), (-7.512432452440564, 'useless'), (-6.836375038275021, 'worst')]\n"
     ]
    }
   ],
   "source": [
    "print(weights[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(7.078804798393313, 'favorit'), (7.524372259001453, 'best'), (8.034549606799494, 'awesom'), (8.268230749297278, 'excel'), (9.160219776882153, 'easi'), (9.376639017778011, 'perfectli'), (9.402134420121362, 'highli'), (10.775171638638696, 'perfect'), (13.880447133070883, 'great'), (15.561025823615415, 'love')]\n"
     ]
    }
   ],
   "source": [
    "print(weights[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "positiveWords = []\n",
    "negativeWords = []\n",
    "for item in weights[:10]:\n",
    "    w = item[1]\n",
    "    negativeWords.append(w)\n",
    "for item in weights[-10:]:\n",
    "    w = item[1]\n",
    "    positiveWords.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_list = []\n",
    "test_labels = []\n",
    "with open('balance_test.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        sent, label = line.strip('\\n').split('\\t')\n",
    "        test_labels.append(int(label))\n",
    "        words = sent.split(' ')\n",
    "        pure_words = []\n",
    "        for w in words:\n",
    "            if w not in string.punctuation:\n",
    "                pure_words.append(w)\n",
    "        test_sent_list.append(pure_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_uniword_tfidf = defaultdict(dict)\n",
    "for word in uniwords:\n",
    "    test_uniword_tfidf[word]['idf'] = calc_idf(word, test_sent_list)\n",
    "sentId = 0\n",
    "for sent in test_sent_list:\n",
    "    for word in sent:\n",
    "        if word in uniwords:\n",
    "            test_uniword_tfidf[word][sentId] = calc_tf(word, sent)\n",
    "    sentId += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "sentId = 0\n",
    "for sent in test_sent_list:\n",
    "    feat = [0]*len(uniwords)\n",
    "    for word in sent:\n",
    "        if word in uniwords:\n",
    "            idf = test_uniword_tfidf[word]['idf']\n",
    "            tf = test_uniword_tfidf[word][sentId]\n",
    "            feat[uniwordId[word]] = tf*idf\n",
    "    test_X.append(feat)\n",
    "    sentId += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8218440954043048\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for y, p in zip(test_labels, list(pred)):\n",
    "    if y == p:\n",
    "        correct += 1\n",
    "acc = correct/len(test_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add positive and negative words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "posId = dict(zip(positiveWords, range(len(positiveWords))))\n",
    "negId = dict(zip(negativeWords, range(len(negativeWords))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_X = []\n",
    "for sent, vector in zip(sent_list, train_X):\n",
    "    posVec = [0]*len(positiveWords)\n",
    "    negVec = [0]*len(negativeWords)\n",
    "    posAppear = set()\n",
    "    negAppear = set()\n",
    "    for w in sent:\n",
    "        if w in positiveWords:\n",
    "            posVec[posId[w]] += 1\n",
    "            posAppear.add(w)\n",
    "        if w in negativeWords:\n",
    "            negVec[negId[w]] += 1\n",
    "            negAppear.add(w)\n",
    "    posFreq = len(posAppear)/len(positiveWords)\n",
    "    negFreq = len(negAppear)/len(negativeWords)\n",
    "    new_v = vector + posVec + [posFreq] + negVec + [negFreq]\n",
    "    new_train_X.append(new_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022\n"
     ]
    }
   ],
   "source": [
    "print(len(new_train_X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_X = []\n",
    "for sent, vector in zip(test_sent_list, test_X):\n",
    "    posVec = [0]*len(positiveWords)\n",
    "    negVec = [0]*len(negativeWords)\n",
    "    posAppear = set()\n",
    "    negAppear = set()\n",
    "    for w in sent:\n",
    "        if w in positiveWords:\n",
    "            posVec[posId[w]] += 1\n",
    "            posAppear.add(w)\n",
    "        if w in negativeWords:\n",
    "            negVec[negId[w]] += 1\n",
    "            negAppear.add(w)\n",
    "    posFreq = len(posAppear)/len(positiveWords)\n",
    "    negFreq = len(negAppear)/len(negativeWords)\n",
    "    new_v = vector + posVec + [posFreq] + negVec + [negFreq]\n",
    "    new_test_X.append(new_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129046\n",
      "27504\n"
     ]
    }
   ],
   "source": [
    "print(len(new_train_X))\n",
    "print(len(new_test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(new_train_X, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(new_test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8232984293193717\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for y, p in zip(test_labels, list(pred)):\n",
    "    if y == p:\n",
    "        correct += 1\n",
    "acc = correct/len(test_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add text features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of words in one sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_X2 = []\n",
    "for sent, vector in zip(sent_list, new_train_X):\n",
    "    word_num = len(sent)\n",
    "    new_v = vector + [word_num]\n",
    "    new_train_X2.append(new_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_X2 = []\n",
    "for sent, vector in zip(test_sent_list, new_test_X):\n",
    "    word_num = len(sent)\n",
    "    new_v = vector + [word_num]\n",
    "    new_test_X2.append(new_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(new_train_X2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(new_test_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8223531122745782\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for y, p in zip(test_labels, list(pred)):\n",
    "    if y == p:\n",
    "        correct += 1\n",
    "acc = correct/len(test_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avg word length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_X2 = []\n",
    "for sent, vector in zip(sent_list, new_train_X):\n",
    "    word_len_sum = 0\n",
    "    for w in sent:\n",
    "        word_len_sum += len(w)\n",
    "    if len(sent) != 0:\n",
    "        avg_word_len = word_len_sum/len(sent)\n",
    "    else:\n",
    "        avg_word_len = 0\n",
    "    new_v = vector + [avg_word_len]\n",
    "    new_train_X2.append(new_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_X2 = []\n",
    "for sent, vector in zip(test_sent_list, new_test_X):\n",
    "    word_len_sum = 0\n",
    "    for w in sent:\n",
    "        word_len_sum += len(w)\n",
    "    if len(sent) != 0:\n",
    "        avg_word_len = word_len_sum/len(sent)\n",
    "    else:\n",
    "        avg_word_len = 0\n",
    "    new_v = vector + [avg_word_len]\n",
    "    new_test_X2.append(new_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(new_train_X2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(new_test_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8229348458406051\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for y, p in zip(test_labels, list(pred)):\n",
    "    if y == p:\n",
    "        correct += 1\n",
    "acc = correct/len(test_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "number of sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sent_count = []\n",
    "with open('balance_train.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        sent, _ = line.strip('\\n').split('\\t')\n",
    "        words = sent.split(' ')\n",
    "        cur_s = 0\n",
    "        for w in words:\n",
    "            if w == '.' or w == '?' or w == '!' or w == ',':\n",
    "                cur_s += 1\n",
    "        if sent != \"\" and cur_s == 0:\n",
    "            cur_s = 1\n",
    "        train_sent_count.append(cur_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_X2 = []\n",
    "for sent_c, vector in zip(train_sent_count, new_train_X):\n",
    "    new_v = vector + [sent_c]\n",
    "    new_train_X2.append(new_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(new_train_X2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sent_count = []\n",
    "with open('balance_test.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        sent, _ = line.strip('\\n').split('\\t')\n",
    "        words = sent.split(' ')\n",
    "        cur_s = 0\n",
    "        for w in words:\n",
    "            if w == '.' or w == '?' or w == '!' or w == ',':\n",
    "                cur_s += 1\n",
    "        if sent != \"\" and cur_s == 0:\n",
    "            cur_s = 1\n",
    "        test_sent_count.append(cur_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_X2 = []\n",
    "for sent_c, vector in zip(test_sent_count, new_test_X):\n",
    "    new_v = vector + [sent_c]\n",
    "    new_test_X2.append(new_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(new_test_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8229348458406051\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for y, p in zip(test_labels, list(pred)):\n",
    "    if y == p:\n",
    "        correct += 1\n",
    "acc = correct/len(test_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "avg number of words in a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_avgword_count = []\n",
    "with open('balance_train.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        sent, _ = line.strip('\\n').split('\\t')\n",
    "        words = sent.split(' ')\n",
    "        cur_word_c = 0\n",
    "        cur_s_c = 0\n",
    "        for w in words:\n",
    "            if w == '.' or w == '?' or w == '!' or w == ',':\n",
    "                cur_s_c += 1\n",
    "            else:\n",
    "                cur_word_c += 1\n",
    "        if sent != \"\" and cur_s_c == 0:\n",
    "            cur_s_c = 1\n",
    "        if sent == \"\":\n",
    "            train_avgword_count.append(0)\n",
    "        else:\n",
    "            train_avgword_count.append(cur_word_c/cur_s_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train_X2 = []\n",
    "for sent_c, vector in zip(train_avgword_count, new_train_X):\n",
    "    new_v = vector + [sent_c]\n",
    "    new_train_X2.append(new_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_avgword_count = []\n",
    "with open('balance_test.tsv', 'r') as f:\n",
    "    for line in f:\n",
    "        sent, _ = line.strip('\\n').split('\\t')\n",
    "        words = sent.split(' ')\n",
    "        cur_word_c = 0\n",
    "        cur_s_c = 0\n",
    "        for w in words:\n",
    "            if w == '.' or w == '?' or w == '!' or w == ',':\n",
    "                cur_s_c += 1\n",
    "            else:\n",
    "                cur_word_c += 1\n",
    "        if sent != \"\" and cur_s_c == 0:\n",
    "            cur_s_c = 1\n",
    "        if sent == \"\":\n",
    "            test_avgword_count.append(0)\n",
    "        else:\n",
    "            test_avgword_count.append(cur_word_c/cur_s_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_X2 = []\n",
    "for sent_c, vector in zip(test_avgword_count, new_test_X):\n",
    "    new_v = vector + [sent_c]\n",
    "    new_test_X2.append(new_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression().fit(new_train_X2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = clf.predict(new_test_X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8239528795811518\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for y, p in zip(test_labels, list(pred)):\n",
    "    if y == p:\n",
    "        correct += 1\n",
    "acc = correct/len(test_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
