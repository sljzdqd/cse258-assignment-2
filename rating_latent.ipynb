{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                         \n",
    "from collections import defaultdict\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "import numpy\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Office_Products_5.csv\")             \n",
    "data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[:int(0.85*len(data))]\n",
    "data = data[int(0.85*len(data)):]   #test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr4 = []\n",
    "tr5 = []\n",
    "tr_other = []\n",
    "for d in data:\n",
    "    if d[2] == 4:\n",
    "        tr4.append(d)\n",
    "    elif d[2] == 5:\n",
    "        tr5.append(d)\n",
    "    else:\n",
    "        tr_other.append(d)\n",
    "data = tr_other + tr4[:10000] + tr5[:10000]\n",
    "random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr4 = []\n",
    "tr5 = []\n",
    "tr_other = []\n",
    "for d in train:\n",
    "    if d[2] == 4:\n",
    "        tr4.append(d)\n",
    "    elif d[2] == 5:\n",
    "        tr5.append(d)\n",
    "    else:\n",
    "        tr_other.append(d)\n",
    "train = tr_other + tr4[:50000] + tr5[:50000]\n",
    "random.shuffle(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataf = pd.DataFrame.from_records(data)\n",
    "dataf.columns = ['reviewerID', 'asin','overall']\n",
    "trainf = pd.DataFrame.from_records(train)\n",
    "trainf.columns = ['reviewerID', 'asin','overall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewsPerUser = defaultdict(list)\n",
    "reviewsPerItem = defaultdict(list)\n",
    "for d in data:\n",
    "    user,item = d[0], d[1]\n",
    "    reviewsPerUser[user].append(d)\n",
    "    reviewsPerItem[item].append(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple (bias only) latent factor-based recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(data)\n",
    "nUsers = len(reviewsPerUser)\n",
    "nItems = len(reviewsPerItem)\n",
    "users = list(reviewsPerUser.keys())\n",
    "items = list(reviewsPerItem.keys())\n",
    "alpha = sum([d[2] for d in data]) / len(data)\n",
    "labels = [d[2] for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(predictions, labels):\n",
    "    differences = [(x-y)**2 for x,y in zip(predictions,labels)]\n",
    "    return sum(differences) / len(differences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item):\n",
    "    return alpha + userBiases[user] + itemBiases[item]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):\n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    alpha = theta[0]\n",
    "    userBiases = dict(zip(users, theta[1:nUsers+1]))\n",
    "    itemBiases = dict(zip(items, theta[1+nUsers:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in data]\n",
    "    cost = MSE(predictions, labels)\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    for u in userBiases:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "    for i in itemBiases:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(data)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    for d in data:\n",
    "        u,i = d[0], d[1]\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - d[2]\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    return numpy.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.7930627363636482\n",
      "MSE = 1.7349223215285619\n",
      "MSE = 2.8043078245334043\n",
      "MSE = 1.6795845118470718\n",
      "MSE = 1.5497686449877404\n",
      "MSE = 1.54750179717496\n",
      "MSE = 1.5390552507881587\n",
      "MSE = 1.443921923461243\n",
      "MSE = 1.3942257831204012\n",
      "MSE = 1.3564022816190109\n",
      "MSE = 1.3392963700607183\n",
      "MSE = 1.3176841699818578\n",
      "MSE = 1.304251715870892\n",
      "MSE = 1.3026225885271114\n",
      "MSE = 1.3068176757029466\n",
      "MSE = 1.3082436620318303\n",
      "MSE = 1.3086929797073603\n",
      "MSE = 1.294267973614376\n",
      "MSE = 1.3030153039305588\n",
      "MSE = 1.298763286329454\n",
      "MSE = 1.2933768873836964\n",
      "MSE = 1.2923834189092662\n",
      "MSE = 1.2923129425017659\n",
      "MSE = 1.2681034276828804\n",
      "MSE = 1.2867813928446419\n",
      "MSE = 1.2898642401478653\n",
      "MSE = 1.2916810753625214\n",
      "MSE = 1.290576569394126\n",
      "MSE = 1.2911661154622958\n",
      "MSE = 1.2900320506174994\n",
      "MSE = 1.2892082700378702\n",
      "MSE = 1.2885779672951738\n",
      "MSE = 1.2887383122967884\n",
      "MSE = 1.2889769333730619\n",
      "MSE = 1.2895425509351979\n",
      "MSE = 1.2898682309386658\n",
      "MSE = 1.29032624896914\n",
      "MSE = 1.289166756806326\n",
      "MSE = 1.2898566288762834\n",
      "MSE = 1.2893411783571764\n",
      "MSE = 1.2893622628761834\n",
      "MSE = 1.2893012187562842\n",
      "MSE = 1.2892893273276789\n",
      "MSE = 1.2892985741552305\n",
      "MSE = 1.289253362993551\n",
      "MSE = 1.289268999074504\n",
      "MSE = 1.2892321872757238\n",
      "MSE = 1.2892098721179475\n",
      "MSE = 1.289207691884063\n",
      "MSE = 1.289247487500023\n",
      "MSE = 1.2892558042510505\n",
      "MSE = 1.2895268515339653\n",
      "MSE = 1.2892906372024575\n",
      "MSE = 1.2893269846293598\n",
      "MSE = 1.2893144476082214\n",
      "MSE = 1.289321858699795\n",
      "MSE = 1.2893149038720613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.31651145, -0.00844758,  0.02683877, ..., -0.00867198,\n",
       "         0.01871117, -0.00918939]),\n",
       " 1.4641853485509875,\n",
       " {'grad': array([ 2.78781354e-05, -5.95337578e-09, -3.83187053e-08, ...,\n",
       "         -7.95177502e-09, -1.55812360e-08,  1.05613356e-08]),\n",
       "  'task': b'CONVERGENCE: REL_REDUCTION_OF_F_<=_FACTR*EPSMCH',\n",
       "  'funcalls': 57,\n",
       "  'nit': 48,\n",
       "  'warnflag': 0})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + [0.0]*(nUsers+nItems),\n",
    "                             derivative, args = (labels, 0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complete latent factor model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha =  sum([d[2] for d in data]) / len(data)\n",
    "userBiases = defaultdict(float)\n",
    "itemBiases = defaultdict(float)\n",
    "userGamma = {}\n",
    "itemGamma = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for u in reviewsPerUser:\n",
    "    userGamma[u] = [random.random() * 0.1 - 0.05 for k in range(K)]\n",
    "for i in reviewsPerItem:\n",
    "    itemGamma[i] = [random.random() * 0.1 - 0.05 for k in range(K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack(theta):   \n",
    "    global alpha\n",
    "    global userBiases\n",
    "    global itemBiases\n",
    "    global userGamma\n",
    "    global itemGamma\n",
    "    index = 0\n",
    "    alpha = theta[index]\n",
    "    index += 1\n",
    "    userBiases = dict(zip(users, theta[index:index+nUsers]))\n",
    "    index += nUsers\n",
    "    itemBiases = dict(zip(items, theta[index:index+nItems]))\n",
    "    index += nItems\n",
    "    for u in users:\n",
    "        userGamma[u] = theta[index:index+K]\n",
    "        index += K\n",
    "    for i in items:\n",
    "        itemGamma[i] = theta[index:index+K]\n",
    "        index += K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inner(x, y):\n",
    "    return sum([a*b for a,b in zip(x,y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(user, item):\n",
    "    return alpha + userBiases[user] + itemBiases[item] + inner(userGamma[user], itemGamma[item])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    predictions = [prediction(d[0], d[1]) for d in data]\n",
    "    cost = MSE(predictions, labels)\n",
    "    print(\"MSE = \" + str(cost))\n",
    "    for u in users:\n",
    "        cost += lamb*userBiases[u]**2\n",
    "        for k in range(K):\n",
    "            cost += lamb*userGamma[u][k]**2\n",
    "    for i in items:\n",
    "        cost += lamb*itemBiases[i]**2\n",
    "        for k in range(K):\n",
    "            cost += lamb*itemGamma[i][k]**2\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative(theta, labels, lamb):\n",
    "    unpack(theta)\n",
    "    N = len(data)\n",
    "    dalpha = 0\n",
    "    dUserBiases = defaultdict(float)\n",
    "    dItemBiases = defaultdict(float)\n",
    "    dUserGamma = {}\n",
    "    dItemGamma = {}\n",
    "    for u in reviewsPerUser:\n",
    "        dUserGamma[u] = [0.0 for k in range(K)]\n",
    "    for i in reviewsPerItem:\n",
    "        dItemGamma[i] = [0.0 for k in range(K)]\n",
    "    for d in data:\n",
    "        u,i = d[0], d[1]\n",
    "        pred = prediction(u, i)\n",
    "        diff = pred - d[2]\n",
    "        dalpha += 2/N*diff\n",
    "        dUserBiases[u] += 2/N*diff\n",
    "        dItemBiases[i] += 2/N*diff\n",
    "        for k in range(K):\n",
    "            dUserGamma[u][k] += 2/N*itemGamma[i][k]*diff\n",
    "            dItemGamma[i][k] += 2/N*userGamma[u][k]*diff\n",
    "    for u in userBiases:\n",
    "        dUserBiases[u] += 2*lamb*userBiases[u]\n",
    "        for k in range(K):\n",
    "            dUserGamma[u][k] += 2*lamb*userGamma[u][k]\n",
    "    for i in itemBiases:\n",
    "        dItemBiases[i] += 2*lamb*itemBiases[i]\n",
    "        for k in range(K):\n",
    "            dItemGamma[i][k] += 2*lamb*itemGamma[i][k]\n",
    "    dtheta = [dalpha] + [dUserBiases[u] for u in users] + [dItemBiases[i] for i in items]\n",
    "    for u in users:\n",
    "        dtheta += dUserGamma[u]\n",
    "    for i in items:\n",
    "        dtheta += dItemGamma[i]\n",
    "    return numpy.array(dtheta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE = 1.793077624531897\n",
      "MSE = 1.7364904992624735\n",
      "MSE = 3.022247568264985\n",
      "MSE = 1.6820334149774039\n",
      "MSE = 1.5462013523386424\n",
      "MSE = 1.5436182874447077\n",
      "MSE = 1.5339822382166852\n",
      "MSE = 1.4281174587497003\n",
      "MSE = 1.3788760616968054\n",
      "MSE = 1.3353908056682389\n",
      "MSE = 1.317377988094165\n",
      "MSE = 1.295659097635261\n",
      "MSE = 1.2886645892604183\n",
      "MSE = 1.2941245880131866\n",
      "MSE = 1.2980712819475477\n",
      "MSE = 1.3005444643291082\n",
      "MSE = 1.3029727065926633\n",
      "MSE = 1.294425482362959\n",
      "MSE = 1.2887002515796606\n",
      "MSE = 1.2839539686833157\n",
      "MSE = 1.2820820484960798\n",
      "MSE = 1.2862037421259636\n",
      "MSE = 1.287443438127511\n",
      "MSE = 1.2887584573052338\n",
      "MSE = 1.290036610990684\n",
      "MSE = 1.289761915279949\n",
      "MSE = 1.2880751741052996\n",
      "MSE = 1.2874786876845201\n",
      "MSE = 1.2875287254245396\n",
      "MSE = 1.2882136059971223\n",
      "MSE = 1.288544085165325\n",
      "MSE = 1.2887433650910787\n",
      "MSE = 1.289160990808683\n",
      "MSE = 1.2892512182991125\n",
      "MSE = 1.2878943590518963\n",
      "MSE = 1.289005765713097\n",
      "MSE = 1.2890327326555933\n",
      "MSE = 1.2891374335779524\n",
      "MSE = 1.2885965034904212\n",
      "MSE = 1.2905719732958836\n",
      "MSE = 1.2886522330175614\n",
      "MSE = 1.2889283746175006\n",
      "MSE = 1.2890441040380096\n",
      "MSE = 1.2891803616225872\n",
      "MSE = 1.2891749201741627\n",
      "MSE = 1.289186015959763\n",
      "MSE = 1.289225145027632\n",
      "MSE = 1.2892743479401114\n",
      "MSE = 1.2892836702871238\n",
      "MSE = 1.2892826343501884\n",
      "MSE = 1.2892814318652468\n",
      "MSE = 1.289278900559865\n",
      "MSE = 1.2892733651568078\n",
      "MSE = 1.2892308256979863\n",
      "MSE = 1.2892475316007317\n",
      "MSE = 1.2892636108852822\n",
      "MSE = 1.2892878069652114\n",
      "MSE = 1.2893234244292853\n",
      "MSE = 1.2893362252534497\n",
      "MSE = 1.2893262992508046\n",
      "MSE = 1.289474468531322\n",
      "MSE = 1.2893486835240722\n",
      "MSE = 1.2893505101019866\n",
      "MSE = 1.2893430432472621\n",
      "MSE = 1.2893353266324845\n",
      "MSE = 1.2892919761876693\n",
      "MSE = 1.2893161182550665\n",
      "MSE = 1.289313044769828\n",
      "MSE = 1.2893158882208162\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 3.31650101e+00, -8.44328403e-03,  2.68601752e-02, ...,\n",
       "         7.59092016e-06, -3.25352584e-06,  6.02116384e-06]),\n",
       " 1.4641853539213276,\n",
       " {'grad': array([ 9.74672190e-06,  3.08381540e-09,  2.99047675e-08, ...,\n",
       "          1.55056668e-08, -6.56288632e-09,  1.18736817e-08]),\n",
       "  'task': b'CONVERGENCE: NORM_OF_PROJECTED_GRADIENT_<=_PGTOL',\n",
       "  'funcalls': 69,\n",
       "  'nit': 61,\n",
       "  'warnflag': 0})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scipy.optimize.fmin_l_bfgs_b(cost, [alpha] + # Initialize alpha\n",
    "                                   [0.0]*(nUsers+nItems) + # Initialize beta\n",
    "                                   [random.random() * 0.1 - 0.05 for k in range(K*(nUsers+nItems))], # Gamma\n",
    "                             derivative, args = (labels, 0.001))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cornac\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "SEED = 42\n",
    "NUM_FACTORS = 2000\n",
    "NUM_EPOCHS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = trainf\n",
    "test = dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/cornac/data/dataset.py:338: UserWarning: 2091 duplicated observations are removed!\n",
      "  warnings.warn('%d duplicated observations are removed!' % dup_count)\n"
     ]
    }
   ],
   "source": [
    "train_set = cornac.data.Dataset.from_uir(train.itertuples(index=False), seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpr = cornac.models.BPR(\n",
    "    k=NUM_FACTORS,\n",
    "    max_iter=NUM_EPOCHS,\n",
    "    learning_rate=0.01,\n",
    "    lambda_reg=0.001,\n",
    "    verbose=True,\n",
    "    seed=SEED\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [10:13<00:00,  1.63it/s, correct=99.87%, skipped=0.02%]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization finished!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cornac.models.bpr.recom_bpr.BPR at 0x123403450>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpr.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating(\n",
    "        model,\n",
    "        data,\n",
    "        usercol,\n",
    "        itemcol,\n",
    "        predcol,\n",
    "):\n",
    "    uid_map = model.train_set.uid_map\n",
    "    iid_map = model.train_set.iid_map\n",
    "    predictions = [\n",
    "        [\n",
    "            getattr(row, usercol),\n",
    "            getattr(row, itemcol),\n",
    "            model.rate(user_idx=uid_map.get(getattr(row, usercol), len(uid_map)),\n",
    "                       item_idx=iid_map.get(getattr(row, itemcol), len(iid_map)))\n",
    "        ]\n",
    "        for row in data.itertuples()\n",
    "    ]\n",
    "    predictions = pd.DataFrame(data=predictions, columns=[usercol, itemcol, predcol])\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = predict_rating(bpr, train, usercol='reviewerID', itemcol='asin', predcol='prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE for Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_rating_true_pred(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user,\n",
    "    col_item,\n",
    "    col_rating,\n",
    "    col_prediction,\n",
    "):\n",
    "\n",
    "    # pd.merge will apply suffixes to columns which have the same name across both dataframes\n",
    "    suffixes = [\"_true\", \"_pred\"]\n",
    "    rating_true_pred = pd.merge(\n",
    "        rating_true, rating_pred, on=[col_user, col_item], suffixes=suffixes\n",
    "    )\n",
    "    if col_rating in rating_pred.columns:\n",
    "        col_rating = col_rating + suffixes[0]\n",
    "    if col_prediction in rating_true.columns:\n",
    "        col_prediction = col_prediction + suffixes[1]\n",
    "    return rating_true_pred[col_rating], rating_true_pred[col_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(\n",
    "    rating_true,\n",
    "    rating_pred,\n",
    "    col_user,\n",
    "    col_item,\n",
    "    col_rating,\n",
    "    col_prediction,\n",
    "):\n",
    "    y_true, y_pred = merge_rating_true_pred(\n",
    "        rating_true=rating_true,\n",
    "        rating_pred=rating_pred,\n",
    "        col_user=col_user,\n",
    "        col_item=col_item,\n",
    "        col_rating=col_rating,\n",
    "        col_prediction=col_prediction,\n",
    "    )\n",
    "    return numpy.sqrt(mean_squared_error(y_true, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.834058282640287\n"
     ]
    }
   ],
   "source": [
    "print(rmse(test, prediction, 'reviewerID','asin', 'overall', 'prediction'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
